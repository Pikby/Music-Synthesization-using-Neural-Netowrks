import sys
import re
import numpy as np
import pandas as pd
import music21
from glob import glob
import IPython
from tqdm import tqdm
import pickle
from keras.utils import np_utils
from keras.models import Sequential
from keras.layers import Activation, Dense, LSTM, Dropout, Flatten
from keras.callbacks import ModelCheckpoint
from music21 import converter, instrument, note, chord, stream
import random

import network

def generate():
    with open('data/notes', 'rb') as filepath:
        notes = pickle.load(filepath)

    pitchnames = sorted(set(item for item in notes))
    n_vocab = len(set(notes))



    network_input = network.get_inputSequences(notes, pitchnames, n_vocab)
    normalized_input = np.array(network_input)
    normalized_input = np.reshape(normalized_input, (len(network_input), 100, 1))
    model = network.create_network(normalized_input, n_vocab)
    prediction_output = generate_notes(model, network_input, pitchnames, n_vocab)
    create_midi(prediction_output)




def generate_notes(model, network_input, pitchnames, n_vocab):
    """ Generate notes from the neural network based on a sequence of notes """
    #get a random pattern from a song, then shuffle the pattern for something truly new
    start = np.random.randint(0, len(network_input)-1)
    int_to_note = dict((number, note) for number, note in enumerate(pitchnames))

    pattern = network_input[start]
    print(pattern)
    random.shuffle(pattern)

    prediction_output = []

    print('Generating notes........')

    for note_index in range(100):
        prediction_input = np.reshape(pattern, (1, len(pattern), 1))
        prediction_input = prediction_input / float(n_vocab)

        prediction = model.predict(prediction_input)

        # Predicted output is the argmax(P(h|D))
        index = np.argmax(prediction)
        # Mapping the predicted interger back to the corresponding note
        result = int_to_note[index]
        # Storing the predicted output
        prediction_output.append(result)

        pattern.append(index)
        # Next input to the model
        pattern = pattern[1:len(pattern)]

    print('Notes Generated...')
    return prediction_output

def create_midi(prediction_output):
    """ convert the output from the prediction to notes and create a midi file
        from the notes """
    offset = 0
    output_notes = []
    length = 1
    # create note and chord objects based on the values generated by the model
    for pattern in prediction_output:
        # pattern is a chord
        print(pattern)
        code,strlength = pattern.split('L')
        try:
            length = float(strlength)
        except:
            length = 1
        if('R' in code):
            str  = pattern.replace('R','')
            print(str)
            offset += length
        elif ('.' in code) or code.isdigit():
            notes_in_chord = code.split('.')
            notes = []
            for current_note in notes_in_chord:
                new_note = note.Note(int(current_note))
                new_note.storedInstrument = instrument.Piano()
                notes.append(new_note)
            new_chord = chord.Chord(notes)
            new_chord.duration.quarterLength = length
            new_chord.offset = offset
            output_notes.append(new_chord)
            offset += length

        else:
            new_note = note.Note(code)
            new_note.duration.quarterLength = length
            new_note.offset = offset
            new_note.storedInstrument = instrument.Piano()
            output_notes.append(new_note)
            offset += length
        # increase offset each iteration so that notes do not stack
    midi_stream = stream.Stream(output_notes)
    print('Saving Output file as midi....')
    midi_stream.write('midi', fp='generated.mid')

generate()
